{"cells":[{"cell_type":"markdown","id":"b16c46b2","metadata":{"id":"b16c46b2"},"source":["# Computational and Algorithmic Quantification of Neurofeedback Learning\n","## Part II - Reinforcement Learning "]},{"cell_type":"code","execution_count":null,"id":"96ef8442","metadata":{"id":"96ef8442"},"outputs":[],"source":["from numpy import exp\n","import random\n","import numpy as np\n","import pandas as pd\n","from random import choice\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","id":"2c44796a","metadata":{"id":"2c44796a"},"source":["We will run simulations on the Q-learning algorithm that we adjusted for high level NF learning (as explained in the introduction).\n","This way we can learn about the different parameters that guide learning.\n","\n","The Q-learning algorithm is as follows:\n","\n","For every trial:\n","1. Softmax choice of action: \n","![softmax.png](data:image/png;base64,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)\n","\n","2. Observe reward r(n); compute the reward prediction error (δ):\n","![reward.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAxgAAABkCAMAAAAyq2ZxAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAPUExURQAAAAAAAAAAAAAAAAAAAE8O540AAAAEdFJOUwA8drgiPZ+gAAAACXBIWXMAADLAAAAywAEoZFrbAAAKAElEQVR4Xu2d7XrjKgyE10nv/5qPRhIgMK6NY3qe2PP+2AqMAX0MTpu0+48QQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEXM7r/SO8X958Hq/34tYjeb8e7f4WC1Rh3K8+Fhf9L6pfMOK2h8LrgHOI0HNPxS2gCxWEVZB13oSg+c3Uw+0bPzB+8TyzQD0/fGrUoC7MsjIy+xao1F/Lkh4bndTnY+GmaMkfOO2OPFieBSojFYZWids3QJ8FbpvoVwq4mccrzO0jHt49EsMgIPmokFK6z7ERdZFKxBuJ21eDPimPuUhlNMR4SHBu87ICLw5ionsvKu5eC5LPNgzbQBl8NVXAoXLDF9lIc+2Xnp6rHjfvCfyD197cARq6YSWc5aaPUJWB28bqkXH7I1I8XgaEcfsH6CAoodvFQx8YTdWjK9bIIx4YI8LgI6PmjsrQx0OTZH2IFLFgSJQOriakqTOArw2NPjBGhDE09gH0Ttd54I3m9M6BvrM05W0EuNTmWEu9lHn7wMDVhDS/XhiSVmwdLhyNMHyekY3vxN73/KuA6LFtxaaCFGYJo61oXa90rkbY1gSTqm/va78LEXfgB3w4GmG4/LX+Xo0e2oiet+eSik/Cn3QxY2Gde5XiajX43YwIm8vNPzovrkdCoH4MOYHBbj4cVJAckKiB9oDdJ7/a6LKqS+GdFnth5cWW92tXckAY2EVbMDog7wjm1+oCu9fNW7QP0gvKI8kvKuXr8fAlhoUhupB/9axe7AWL2MPLHkB3tpoYac95h+1mRvUk6Bg0vrdIcmCHhKGpcfvJlANCK0mtAfSmTToBXvQsRsXJrbpw+noxurNfhdF/VukIQUzdpfV+Idi9WUPC6EflcaB8UsyG4vcZpqeph/G+MDCiUwKujPe3l4i45+4PC2P4fLwdVe61lNyeTL9qL+WYMDp70MoQ3jL2i3UBN9yE08c9ge9uPhcEIZ/bf3hWYKXBpfSWTXxQYF8YWwep3qlM1YUtM20J8S5lFiuNCSPXxENpzkyEpFcp13Mi+LhlGx8UOC8MGwS8PQn9hdpZwpBTLk9NYYzSxADNPxHGmWcTbtnGBwX6woiDN4WR1poeC1ljljBk6pxZCmOQtj7R/BNhNE+qKagwVuWAzn1haGCE2fUhS/xasHLdrVHU+wq/kHltZQCDHy6Mtj4Rkj8RBkpyduy1uNuyqzq3hZFeTB0/Zs+xswR26+YgSdkBv+JgAIWxBULwvwgDC7k5DyzSrqIFk1zcf2LMVsbOCueFIUde8EzdcVsx/zZSjUsURhWCEyFZP7IjG6FfJWoKeuo3O9DtJhc3hZF1MbtCZIHfhIHdujlGo6gm3vpNv0BhbNGEQOP3F8LATRuXLkS31tQdunKJbAkDcfDPG0/Wr8z/mzBOry+eRceqxMKzt7pHYWzRhEBrwczyGxP695i245Tqp88xYeSm/W6G9l0BdlAXllZIXrnZRgKDZBN+rJbtWFuMKiSmoOqvHPrfsHJeHiO7Qc08Z7RXU+lmnbSazbz35zRxp5tKJQxZFCamsXYLBrv5VKp4xaYlFjnzFO9kYpBqRs+/tN0KpfIZVkTeULTy3LZWZzG5Db2pLvMELlvv926Pj5AdMh0Y7zcG6msXu16/dxFsU4ViXXGadLO3wgxdZEDltt5X9qf/tmMyOtjtp4IkleggIhZwfAIWLbHksQGrH8OTVKGXhn4KHR9Cl1WwJb/yOVgnzqYL5wKp95HJO0iVWW6QxltvEjQiaODBqge5DvGgog+j/F6MS9OI2REGRueZUrTR6SbwSyqhnJA43mluc0ebQeseR3fi9lOpYqDR0+wt+kVaogu0Q9YvQcvJbVtCNvKyVXGtn7ATwL+YZDgSmnBx5RjGeA3DFMod1iESFkM3KV/9ah5XNBDcLJ1RDNHuzNRWeJkE/Wm6KocKxn0ojMsy8K0gYB7h8Lg3pGm6CEm7hnXopedti8cS+hz4lPdev4oBuNospnd4H/YJ8j16US1zIGwWl9TATWqEvsorMfOExZax7UzVXIJc8MGYLgVQN+m2gQkqN00YdReW7pc/bn+8MHLE7BVuLBJ0lKQ1Uf2MdqnYE0voAtQt+X4Wf9UZ1kqPdY/GI/ptJO/bmsE1N/NUIVgYblb0SswczWAv6TpmWpv1ZsWMY8ogwXbtDUPH1F2Yog5GYj30iegp6thPoRIIpneI1Y/hSbBYXfxY3ayqFi4gOth46DpwG1gBAbTcVPRyqHQFt6fAZFvGnBJGJkSgCkZcPNgYE+ZI/sYfk7lb9f8PIh3dpDbzPZcXfu0AUWuKRno9PjH/V9CWY1U3Mf0XkX942ngoNL1eQQJabip6ud2cOhJIwkhj0GfWVcKIhO6QHbsGvCPu0nsUaXaT2sxHWkp8qvRMIawwKS0ybW9iFM3AcjvC0BqHLzZlUMMxYSyvpGHv+FUYPl+zp8PIbV3PpX+lVVIIqZTQTw5VWSFW0JVYDa9nRq+bB2iKEJOuiwuD0IurKW7RrdAd7fA+xrYw3IxI76nsyH09YRRdky4hJ2dDf5ySDCw7QxhaVh03+rW9xSFh2FJKXm9fGBiB//mpivwBYUjvueRgOTcj0n1uvqdQAj7/DAllI1Yn+1eg5brOOboPK7GpzU1h2Ldt4bu2XWFgQIi3WQeEIfetfTqEzLYh6sPheCQlblV2phBW6KfrClB6uYrCj6dK5z5tbXbv1Q+BNOwKo6+GKvRorGp2YPMNMlt/n5PifxdKhKQazgb/ICX/sYCuxpUh04tVPEL3Uf9aYVTnq78RIc7o14pQcHA2r5ftEOSwSKWFeqMpOUe3vkJmW0lgJBYPpdRqytn5FOxScoTMaOXmcrgQVJwTfRmohlCzSrxVbP0qY/RrDRZVA7eU5bLtQRZ0gJmahVK9WD3FpfdYGqLnda+P1JREuUY+zsQ2yEdKuJj4NGH7Ttw1wBOldkVL8dCCrTB0Rn3fDO+r2RQhcoFU4q8fjMwDcLsaOpF8Xd5vi7chJm6TgOQWVpEhnTUGWNTn+F2QAO8+m/YBhOxZDKec4UYUBpIzMT36XXH7VqaXxL6DKNnO5wOM1G8eOOXNZu8QR8MWdKzZ6Tb/+4c+mcfe4xPexa+lPUbZsxJ7fVmyiQQpx16yU3+a4GKQEje1QNaFOx0tuT0fU1nW49pfHcq1bGSNw0sNo02D8WqkIfZ5c+m2CXw+3VjRor3Z8WE2usKANTPJ5EuRknPrU5J+nC95cfKaevYRIrrIB7w+Jdwm5MmIFsLRC2W4SciTESVQGIS01C+epJVfVxHyYPSnSPbM0B8h8VsMQkD9Qyn+qIcQx38n0t6VIIQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgi5P//+/QdvMzkfkgRnJAAAAABJRU5ErkJggg==)\n","\n","3. Now update the Q value of applied action according to learning rate (α):\n","![update.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA74AAABhCAMAAADGII1UAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAPUExURQAAAAAAAAAAAAAAAAAAAE8O540AAAAEdFJOUwA8drgiPZ+gAAAACXBIWXMAADLAAAAywAEoZFrbAAAMmklEQVR4Xu2d24LbIAxEm6T//83VDAILDL7F3sTbOQ9dGYOQNLJz3e0fIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEKI/4rH8+XWf8nj9XTr80gKt27F4/X6azwffnwaz+T4teD5iQlu/z42JIcCvE6v/AxJsZ7cD0lxMtQ1cerdJ/gdVeWBc7e85W1i0wXxRJ0uftSTFF8jxdkgZMhG/f6edvOhO7vZPx6sXLcz8ta/FSa+XtGH1eHKu76k+BopTgeKeryQ8CwN2TK5DnQ8v6th+E6l2gvT3pThpZWQFF8jxflYuEXN80KvWsar194Yblao3bAGG1O8sBaS4geksEWfedKNaN1klm6+SVssHDdFCQ/7vxOr7PYcowzn0lYex5JigSNS2JrPXL5VWq+TgkAFKk+8/c1GfvOLLRT2ieJuTLKtz1lIip+Q4mOXL7Q7e2d2SF0rjFR3vyP3uFuBsu7oGUy94BFQUhjXS/Gxy5findw3cNk0BEoSy/df3PH39MyRe/4GJMWPSPG5y5f353OvX3hssuEuoY/qIx5m7JAdBj5UkxNg7Ht6Zs/c7XSKKCnW2C/F5y7f869fKt6mj7Fpl/aOz7OOHd6/Z0xPSxZ5bE5hy9y9n0lKisukqNhz+aYvh3jJUdlWn53AXbz/vgsVb/uMm5RBTKlm8DRIDZoeId5N7HNY/JBzV8+gBG6OsClubURSXCVFjS3Y6JyKAM5ncVt9CuZ1vey8G2xPbR36c7vAsEsw8xlcZPgUHg7z+nosfPzY1TOYvKgWtN5ZEklxjRQttskm5/hWF3+5wHbAAh6mUx1s0lrd+TUxc7Iv3EXozu1C1TNoxDZdnJ+GYd63ZVycdHPlyAZ6RYkcuHolxTVSzMBF5OYSDCLVkpfmyj6cswj0fUa3JwBns0pxixwqGqi9XXCCwTBwcN+WQQX4kznR2sLy5EMlgUtJAc6UYs7Gyxducy2xAsXv1ja9brHT4WgOH3phwM+ueJeAr5mzqmdw05iFhEFgJiaf92zgx7FMUvT7eqZblQxcbemQGuwvKcCJUnSw+RvEqbzaimFt7QTc2Q/8a8s42oLlvqtZp6kEX8s9A3teHWRnvGJct8TCTwaTTuYGkP9Ig4Mlwf6SApwnRQ+bv16lupa2xB40+6tYfj639kfWbiw44ea+7JaBq5kvbhB7xs0Apxj4zfI7twyESRYz2nwXh1CDnoGjIyXB/pICnCZFl01lqiOwJdVxBaN9PswppvWfPONMOcH5br8JXC32DO1kVvBGQ65tmbTHZi13YtmV8Hftg/T7iSepl+luwzNuFyTFKmMpCvA3xidFmlJz2viK43vUZBBHHSJmf/ryndrUj6+CzXlVz1gSxfWufcY9AzdrdLfhGbcLkmKVKy5f+AxX2GhaIf1xhWEU9XLOdftN4Gnmiv49+mHP5JqcdB8Zg2gu6hlzPZUcyZzQM+VaWqC7Dc+4XZAUq4ylKMDfGJ8UwXAIoDmck76PMfrjZE2E1NTtN4GnWWT0v9ozPGNsrvNBEM3SHnb+aN+mBAKtI3ta5FZDo0hk4dQiDEBSZM6QootdaWvTm0rjcCkvXLzprt2/gHEurKembr8Jd233jIPjnsmPM0dadQ9rPWNhHOwZTyDQOMIENxuWegYlO1CUWPVCHJQUXS64fBuXy2n7H837++JL4N5bVzYcY4e7QS57oau25Kyl2+Oe4RlwcdMsF++dnjHHbgFkXTliGQZ1bgSuOXb9SorCeVJ0MF9r05v9x3sbDG3xgyOOug3a4zdIwvtBBkM5w2HPlJZZVvR91nrGTh/rGSt8XNhoxiIbftiAs+MmQG12xyQpCidKMcec77t8ub3bc6z4cGeTpoOaNsC9AS+B0BpJGG6OftQzGPc/ZrqQ2xlgk4WewelDPYMM3CTQrFQVz4iefDbkAw0rErA6bm/G1kgKcqYUM8zT2nTzOCXCsi+seHKmRcHKdJ48twFW2b0JfDc1h/upVNVBATlZCJwag6E7+GM/lfHOO3P+fwk43rxpQXKSJ+MoLGxcBSd5t85mPWxWlTdWTQHTxNbpuAVn6qrV8JJyeytM+3dJ4R+oLFUK2MrrpGgx58X3AARdXDKttRWIYqQ3Aozrg/cSe63RdnhvqQuDgakeOJoH5jVIq+N0SvpIOWe/eVYIkHdTB81jQyEBmN2eSQ1D0pAfkLS4s1kXuHUzAddTfHQ/m1PA5CnpHvv/lOCvkyJvbczDDlwtRY3NL74HmMfi8rHt62w2Z5RjqCaYDl0MW+fW6i5z4K1Kv6rdoDoYpMHVxhQ6RkpHcMQ98AbjnhAu7smcmDczO5t0MrfNKp6KmGks09ksbdeKXy8zGLPbDpy42YC5I7mc0e+ejGFaMahYHcNzq8EgDa42vkYKerbpvNB97DNSVITcRoRSWLxbVmBOncNEkzKcM14b580Vv0VoazHOCfuA85A/NwvlCEoXSgTJNKb0uB6y5YJjIE2e1LdVvqJ2ld1MM6Pd89SI35/SkRj7vtkzbp4IvIY47y1FcGLjJSqzy/wE9v1BKUJuI7BZ8ml58hLjiv035AS8laXILe3/wg/b6vngWZS0VXcDSeTsnpHHMDHQpMvq+hzON8oUumMYdgo/pnJNARYjBh3qCq8xomTb3Jmn6MvobWaYHSYZOFulWWflYGs3a7jc7ROh2yrxKiAMlDonvlgKnPCFiDJZXyBFyG0EfdokPLewMBAOPxpaWzcAscdyRjd2/Eqphnrtwp9f8f/FgtncZHDOTcLcSgxprZFjasuJeIO8PBUihbm1Z/xlEJhWVT3T2wzALpOMlEMcSXOaIbhzsybucya/SIoYbLvxNCnnEEfSnGYILtysib43EXIbUkrJdPPR6rIRdABPSdQ0mMhnKiV2ghIU2lpgxzA2zcWRm4SnYxMQLHez2Ed7ZmJaFc3uZsDM6CPnEN5/za8R67dkbcDNGsycxXQKU3mNWEeAGMPYNBdHbhKe/qwUcfNom/lZKUJuY+AV0DPCN0pq+5mUat3YgEczzHAD6S0IY54ZzoTRKRIcuUl4upIKuBYFjIU5cOfmCT3T28xg/d02phQ6C8uQgYluVjT+zuWXSMEaBfzE56UIuS2AKMr9AzeU6maym/Rk6u+r/QwN4btjTEjWMVIp/SCwz2/oB8KwAwwWBs/GYgZzoWee+VPKvEkw+5vNY9rKqGeakM7nF0jB6yrg/j4vRcjt84S0DhZmglrMU8MW2x33esbNCUzi6zqczdUPdY2iVDZDTORNgtnfrHaxh1DcChvujp8H87y1FIPr9H5SXMpUaNTrSGEm4KHnoyv7iE0941uRst96z8DXi89izOj1zHizeVYbGPTM0Rbcwf2laDdP3FCKS5mKdEImg6bB8PyRYEAr26hn0vOu+FpgtWewwkfNyiuDOdjMRo8Vpt8zu8pxlNtL0W6euKMUF4L4pzJ2EtwHdXSHj6kuUcI1Wtm6a22SW4HVngme+2Z/MxvcGnwD3LkZQJHcvJC7S4GD2ZVlDrYG34Ct3Qz8jBTXEbKqaneU1DTwY9ZUaQxvrHvbMzgO3Zd+dEMNWpg17xl48sG4iZnFf3ez9KWWI3R7Zkct3uLmUtSB+sfEN5XiMqasQkXfAF4y0dv2QkU5SVz6SqdsTqdnkEsaxpKyptczmBB6ZhK2s9kb9LLujV3C3aXAnHwxm+3WUXpZb6/Et2IJeO28osfvb4n8mXn7hR8MT3fWBRBH3RDwxjc5TP3kIqgfwRZI4cW/aZ8nlJ6ho+QHb3vmTXAey9J3zzCn3uwwqRSv6ftFBgLrhX4Fd5eCRziFRLKLY3xaiouItTUTv7vQaL0flqr9eNmrNRudkQpdzSttWMbpq8B+AtAb+H8YkCZzbrLLsvRbcHmT7J79ON/sGO7DyXHD+Zs3hT3cW4rixI7faUr34eS4WZpk3xZUMVcmle7CjKiG2yOKrH6cSF8kCn04dRHJKVATtFByg1xyC3AK/dANHeRcOVoSn212CPiYSM64zzuNeBpM0e0RXyCFfzhcbgrHgIuJb5PiHZCFm6zjm4Va4/nuRZEpreXcRIir67sDSXH7i/e2WMtMD5a4QUuKTyEpxF6sS9wCdnTSI4nYjaQQO6me8qtnPomkEHtBz0zP0exoeq9D/CySQuyF75b4Ww98b1Kvtz6FpBC7qd/tvP8HADdGUoj9+F8fsIbRa60PIymEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBDfwZ8//wAQTGUKOaqsPwAAAABJRU5ErkJggg==)\n","\n"]},{"cell_type":"markdown","id":"25d09173","metadata":{"id":"25d09173"},"source":["Below are the free parameters of the model (excuding the reward variance that would vary between targets and could potentially be evaluated from NF data). Each of the parameters defines a feature that confines learning. \n"]},{"cell_type":"code","execution_count":null,"id":"bea84d9f","metadata":{"id":"bea84d9f"},"outputs":[],"source":["N = 100 # number of trials"]},{"cell_type":"markdown","source":["If the practice is too short, subjects might not get enough experience with each type of strategy to reveal the reward distribution of each action\n"],"metadata":{"id":"GA5z5DBIHFhn"},"id":"GA5z5DBIHFhn"},{"cell_type":"code","source":["strategy_vals = [0.6, 0.2, -0.4] # -1 to 1"],"metadata":{"id":"gakW8qszHOxb"},"id":"gakW8qszHOxb","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["These values indicate the latent average reward each strategy produces. Here we assume that specific types of strategies have differing effects on regulation success. This of course is an assumption. The analysis applied in the first part of the workshop supported such hypothesis. However, this may not be the case if the neural target is too easy or too hard to regulate (for instance due to low SNR)"],"metadata":{"id":"Rdrp2R0BHFIe"},"id":"Rdrp2R0BHFIe"},{"cell_type":"code","source":["alpha = 0.05 # [0-1] learning rate"],"metadata":{"id":"vTUai5XfH1lD"},"id":"vTUai5XfH1lD","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This parameter controls the speed of learning, by discounting the update of new information into the Q(A) value function.\n","1 indicates no discounting (the last reward becomes the new Q(A) disregarding previous experience), and 0 does not allow any change.\n"],"metadata":{"id":"ViLeXE41HE11"},"id":"ViLeXE41HE11"},{"cell_type":"code","source":["beta = 5 # [0 - inf] The inverse temperature parameters  "],"metadata":{"id":"hhjr_5u-H8Aq"},"id":"hhjr_5u-H8Aq","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This parameter controls the extent to which subjects focus on maximizing reward locally (for each step), rather than exploring alternative actions with less current utility, or: the exploitation-exploration tradeoff. Low values produce high exploration patterns while high values produce high exploitation patterns. "],"metadata":{"id":"3J2i00z3HEkz"},"id":"3J2i00z3HEkz"},{"cell_type":"markdown","id":"1ebace65","metadata":{"id":"1ebace65"},"source":["First we'll run the algorithm step by step with these parameters\n","\n","Let's assume the subjects are instructed to choose strategies that relate to one out of three emotion regulation strategies:"]},{"cell_type":"code","execution_count":null,"id":"57706292","metadata":{"id":"57706292"},"outputs":[],"source":["# Chosen Strategies\n","Strategies = ['Reappraisal','Suppression','Watch']\n","# initial Q values for each strategy based on a random choice pattern \n","Q_vals = [0.33,0.33,0.34]    \n","\n","Q_vals_update = pd.DataFrame(columns = ['Q(A(reappraisal))','Q(A(suppression))','Q(A(watch))'])\n","A = np.array([],dtype=int)\n","r = np.array([])"]},{"cell_type":"markdown","id":"5ae29f6a","metadata":{"id":"5ae29f6a"},"source":["For an example trial N\n","1. Choose action according to current Q-Values:"]},{"cell_type":"code","execution_count":null,"id":"cee7b8c2","metadata":{"id":"cee7b8c2"},"outputs":[],"source":["# compute choice probabilities per strategy (based on softmax choice rule)\n","p = exp([i*beta for i in Q_vals])/sum(exp([i*beta for i in Q_vals]))\n","        \n","# generate choice according to choice probababilities\n","A = np.append(A, max(np.where(np.append(-0.00001, np.cumsum(p)) < random.uniform(0, 1))[0]))\n","print('Q-Values = '+str(Q_vals))\n","print('Soft Probabilities = '+str(np.round(p,3)))\n","print('Chosen Action = '+Strategies[A[-1]])"]},{"cell_type":"markdown","id":"75420a3a","metadata":{"id":"75420a3a"},"source":["2. Generate reward based on choice:"]},{"cell_type":"code","execution_count":null,"id":"67a330e2","metadata":{"id":"67a330e2"},"outputs":[],"source":["# generate reward distribution based on actual strategy values and some noise\n","mu, sigma = strategy_vals[A[-1]], 0.2 # mean and standard deviation\n","s = np.round(np.random.normal(mu, sigma, 100),2)\n","# choose from distribution \n","r = np.append(r, choice(s))\n","print('Reward = ' + str(r[-1]))"]},{"cell_type":"markdown","id":"b9465940","metadata":{"id":"b9465940"},"source":["3. Update Q-Values base on reward and learning rate"]},{"cell_type":"code","execution_count":null,"id":"089f48d1","metadata":{"id":"089f48d1"},"outputs":[],"source":["delta = r[-1] - Q_vals[A[-1]]  # Prediction error\n","Q_vals[A[-1]] = Q_vals[A[-1]] + alpha * delta # update rule \n","Q_vals_update.loc[1] = Q_vals # log data\n","\n","Q_vals_update"]},{"cell_type":"markdown","id":"6851cf9d","metadata":{"id":"6851cf9d"},"source":["Now let's run this 100 times and look at the results:"]},{"cell_type":"code","execution_count":null,"id":"dd293b03","metadata":{"id":"dd293b03"},"outputs":[],"source":["Q_vals = [0.33,0.33,0.34] \n","Q_vals_update = pd.DataFrame(columns = ['Q(A(reappraisal))','Q(A(suppression))','Q(A(watch))'])\n","A = np.array([],dtype=int)\n","r = np.array([])\n","for n in range(1,N):  \n","    # compute choice probabilities per strategy (based on softmax choice rule)\n","    p = exp([i*beta for i in Q_vals])/sum(exp([i*beta for i in Q_vals]))\n","    \n","    # generate choice according to choice probababilities\n","    A = np.append(A, max(np.where(np.append(-0.00001, np.cumsum(p)) < random.uniform(0, 1))[0]))\n","\n","    # generate reward based on choice\n","    mu, sigma = strategy_vals[A[-1]], 0.2 # mean and standard deviation\n","    s = np.round(np.random.normal(mu, sigma, 100),2)\n","    r = np.append(r, choice(s))        \n","    # update values\n","    delta = r[-1] - Q_vals[A[-1]]\n","    Q_vals[A[-1]] = Q_vals[A[-1]] + alpha * delta\n","    Q_vals_update.loc[n] = Q_vals\n","        \n","data = {'strat_choice':A,'reward':r}    \n","nf_Q_learning_sim = pd.DataFrame(data)"]},{"cell_type":"code","execution_count":null,"id":"b1991d05","metadata":{"id":"b1991d05"},"outputs":[],"source":["fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5))\n","# plot the q-values change over trials\n","ax1.plot(Q_vals_update.iloc[:,0])\n","ax1.plot(Q_vals_update.iloc[:,1])\n","ax1.plot(Q_vals_update.iloc[:,2])\n","ax1.legend(Strategies)\n","ax1.set_title('Q-Values over time')\n","ax1.set_xlabel('Trials')\n","ax1.set_ylabel('Q')\n","# plot rewards over time\n","ax2.plot(nf_Q_learning_sim['reward'])\n","ax2.set_title('Reward over time')\n","ax2.set_xlabel('Trials')\n","ax2.set_ylabel('Reward Value')"]},{"cell_type":"markdown","id":"db6078d3","metadata":{"id":"db6078d3"},"source":["We can observe that with the parameters, the Q-values converge around their expected values, and the reward is increasing with time.\n","\n","Next, the entire simulation is wrapped in a function and we can play with the different parameters:"]},{"cell_type":"code","execution_count":null,"id":"07c8b32a","metadata":{"id":"07c8b32a"},"outputs":[],"source":["def simulate_nf_Qlearning_vals(N, strat_vals, alpha, beta, plot=1):\n","# =============================================================================\n","# This function simulates mental strategies choice and reward data for explicit NF training according to model parameters \n","# INPUTS: \n","#   - N (int): number of neurofeedback trials (cycles) in practice\n","#   - strat_vals (list): model parameters of the real value of strategies for target region regulation\n","#   - alpha (float): learning rate parameter\n","#   - beta (float): free temperature parameter. Govern the extent of exploration of suboptimal strategies\n","#\n","# OUTPUTS: \n","#   - nf_Q_learning_sim (N*2 DataFrame): mental strategies choices (A(n)) and rewards r(n) across trials, simulated according to model parameters \n","#   - Q_vals_update (N*number of strategies DataFrame): a track of how the Q-learning values change across trials       \n","# =============================================================================\n","    from numpy import exp\n","    import random\n","    import numpy as np\n","    import pandas as pd\n","    from random import choice\n","    import matplotlib.pyplot as plt\n","    # initial Q values for each strategy based on a random choice pattern \n","    Q_vals = [0.33,0.33,0.34] # an interesting NF feature that we can test here is the effect of biasing subjects initial preference for strategies via task instruction (e.g. \"use emotion regulation\")\n","    Q_vals_update = pd.DataFrame(columns = ['Q(A(reappraisal))','Q(A(suppression))','Q(A(watch))'])\n","    A = np.array([],dtype=int)\n","    r = np.array([])\n","    for n in range(1,N):\n","        \n","        # compute choice probabilities per strategy (based on softmax choice rule)\n","        p = exp([i*beta for i in Q_vals])/sum(exp([i*beta for i in Q_vals]))\n","        \n","        # generate choice according to choice probababilities\n","        A = np.append(A, max(np.where(np.append(-0.00001, np.cumsum(p)) < random.uniform(0, 1))[0]))\n","\n","        # generate reward based on choice\n","        mu, sigma = strat_vals[A[-1]], 0.2 # mean and standard deviation\n","        s = np.round(np.random.normal(mu, sigma, 100),2)\n","        # implement this part with choices(rewards,weights) but generate weights accordingly...\n","        r = np.append(r, choice(s))        \n","        # update values\n","        delta = r[-1] - Q_vals[A[-1]]\n","        Q_vals[A[-1]] = Q_vals[A[-1]] + alpha * delta\n","        Q_vals_update.loc[n] = Q_vals\n","        \n","    data = {'strat_choice':A,'reward':r}    \n","    nf_Q_learning_sim = pd.DataFrame(data)\n","\n","\n","    if plot:\n","        fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5))\n","        # plot the q-values change over trials\n","        ax1.plot(Q_vals_update.iloc[:,0])\n","        ax1.plot(Q_vals_update.iloc[:,1])\n","        ax1.plot(Q_vals_update.iloc[:,2])\n","        ax1.legend(Strategies)\n","        ax1.set_title('Q-Values over time')\n","        ax1.set_xlabel('Trials')\n","        ax1.set_ylabel('Q')\n","        # plot rewards over time\n","        ax2.plot(nf_Q_learning_sim['reward'])\n","        ax2.set_title('Reward over time')\n","        ax2.set_xlabel('Trials')\n","        ax2.set_ylabel('Reward Value')\n","\n","\n","    return [nf_Q_learning_sim, Q_vals_update] \n","\n","########################"]},{"cell_type":"markdown","source":["Choose different values for the each parameter and see if learning converges. "],"metadata":{"id":"d6BL7HyRLUVJ"},"id":"d6BL7HyRLUVJ"},{"cell_type":"code","execution_count":null,"id":"e55e9e17","metadata":{"id":"e55e9e17"},"outputs":[],"source":["\n","Trials = 20\n","strat_vals = [0.6,0.2,-0.4]\n","alpha = 0.01\n","beta = 5\n","\n","sim, qvals = simulate_nf_Qlearning_vals(N=Trials, strat_vals=strat_vals,alpha=alpha,beta=beta,plot=1)"]},{"cell_type":"code","execution_count":null,"id":"99f57091","metadata":{"id":"99f57091"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}