{"cells":[{"cell_type":"markdown","metadata":{"id":"balrdJZOIe0A"},"source":["# Computational and Algorithmic Quantification of Neurofeedback Learning\n"]},{"cell_type":"markdown","metadata":{"id":"3YTTFPd_H3eQ"},"source":["In order to get access to external files run the following cell and connect your Google Drive to this notebook (accept all permissions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VRPz-DAzHWMC"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"LfjCygdJJPp3"},"source":["The workshop folder should now be accessible at:  */content/drive/MyDrive/rtfin2022-main/rtfin2022-main*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cackcaHHuH3"},"outputs":[],"source":["# list contents of workshop folder\n","workdir = '/content/drive/MyDrive/rtfin2022-main/rtfin2022-main' \n","!ls  /content/drive/MyDrive/rtfin2022-main/rtfin2022-main"]},{"cell_type":"markdown","metadata":{"id":"G1cGKxpCKGRH"},"source":["Run the following cell to make sure we have all the packages needed for the workshop installed."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esg-RcK2KFIv"},"outputs":[],"source":["! pip install -r '/content/drive/MyDrive/rtfin2022-main/rtfin2022-main/requirements.txt'"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"vtglEzQ-LglW","executionInfo":{"status":"ok","timestamp":1666096158773,"user_tz":240,"elapsed":1806,"user":{"displayName":"Guy Gurevitch","userId":"14194484013058517598"}}},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from math import pi\n","import math"]},{"cell_type":"markdown","metadata":{"id":"jVtlByjHLf6W"},"source":["# Section 1 - Descriptive statistics of the mental space subjects use during NF practice \n","First, Let's load a sample dataset of the Mental Strategies Questionnaire for Neurofeedback (MSQ-NF) and have a look at the data. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOyQvVqDZ466"},"outputs":[],"source":["data = pd.read_excel(workdir+'/database_msq_ratings_reg_success.xlsx');\n","data.head()"]},{"cell_type":"markdown","metadata":{"id":"hTXqZtoYa6Iw"},"source":["In each msq feature column, there is either **0** - which indicates a 'No' answer, **1** - which indicates 'Yes', or **NaN** - which \n","indicates that the rater did not have enough information to conclude whether or not this feature was present in the strategy. \n","Hence, for some features which were harder to interpret for the raters, the data is sparse (i.e. a lot of NaN values).\n","\n","*Importantly, sparsity is a characteristic of the current dataset (stemming from 3rd person ratings). When the subjects themselves fill the MSQ following each training session, the data is much less sparse (rarely containing NaN values).\n","\n","---\n","\n","\n","## Let's plot regulation success:\n","***Q-hat*** (QÌ‚) is a non-parametric effect size, which is the outcome measure we use to quantify regulation *PER TRIAL*, in order to deal with extreme values uniformely.\n","- Below 0.5 - target (efp amygdala/mesolimbic) down regulation (i.e regulate < rest) \n","- Above 0.5 - target (efp amygdala/mesolimbic) up regulation (i.e regulate > rest)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7imMENTa4Ws"},"outputs":[],"source":["fig=plt.hist(data['Qhat'], bins = 20)\n","fig=plt.axvline(0.5,linestyle='--',color='black')"]},{"cell_type":"markdown","metadata":{"id":"8Wc9QiBbcqAf"},"source":["***Cohen's D*** is a parametric effect size, used here for visulatization purposes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-AUBMHDcr3y"},"outputs":[],"source":["fig=plt.hist(data['Cohens_D'], bins = 20, range=(-5,5)) \n","fig=plt.axvline(0,linestyle='--',color='black')"]},{"cell_type":"markdown","source":["We can see that the whole dataset is skewed towards downregulation (Q-hat < 0.5, Cohen's D < 0), which makes sense as two thirds of the data is taken from amygdala down-regulation training "],"metadata":{"id":"xBkXCc6I1f_8"}},{"cell_type":"markdown","metadata":{"id":"3WmZoACsdYuk"},"source":["### We want to examine the frequency of mental features. This can be interesting from various reasons:\n","- Do certain groups (e.g. target vs. control groups, patients vs. healthy subjects etc.) use different features?\n","- Do successful regulation trials are characterized by a mental space that differs from that of unsuccessful regulation trials?\n","- Does the mental space change along practice (i.e. trials at the end compared to the beginning of training)?\n","\n","#### Let's look at option 1 - comparing two different training groups, one practicing amygdala efp downregulation (N=4100), and the other reward mesolimbic upregulation (N=2400). \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jurlmBeWd41j"},"outputs":[],"source":["# The MSQ is divided into three meta-categories, which we will plot seperately \n","content_features = ['Vision_Exteroception', 'Auditory_Exteroception', 'Smell_Exteroception',\n","           'Taste_Exteroception', 'Tactile_Exteroception', 'Pulse', 'Viceral_sensations',\n","           'Breathing', 'Muscle_sensation', 'Vision_Imagery', 'Auditory_Imagery', \n","           'Smell_Imagery', 'Taste_Imagery', 'Tactile_Imagery', 'Memory_or_Imaginative',\n","           'Motor_Imagery', 'Lingual', 'Conceptual_Arithmetic','Intercation_with_other_people']\n","psychological_dimensions_features = ['Arousal', 'Valence']\n","manner_features = [ 'Rhythmic', 'Interface_Engaged_Detached', 'Involving_one_or_many_strategies']\n","\n","# organize data for plotting frequencies of msq_features use:\n","def organize_data_for_plotting(df, features:list):\n","    #create df of specific meta category\n","    #important to add neural target column to seperate groups \n","    meta_category = df[features]\n","    meta_category = meta_category.join(df['Neural_Target'])\n","    \n","    #split data by neural target\n","    amyg = meta_category[meta_category['Neural_Target'] ==1]\n","    mesolimbic = meta_category[(meta_category['Neural_Target'] ==3) | (meta_category['Neural_Target'] ==4)]\n","    \n","    #create value count for each neural target\n","    def create_value_count(df, neural_target:str):\n","\n","        df_count = df.apply(pd.Series.value_counts)\n","        df_count = df_count.transpose()\n","        df_count.reset_index(inplace = True)\n","        df_count.rename(columns = {'index': 'Feature', 0: 'No', 1:'Yes'}, inplace= True)\n","        df_count['total_count'] = len(df)\n","        df_count['yes_proportion'] = df_count['Yes'] / df_count['total_count']\n","        df_count['no_proportion'] = df_count['No'] / df_count['total_count']\n","        df_count['Neural_Target'] = neural_target\n","        df_count = df_count.drop(df_count[df_count['Feature'] == 'Neural_Target'].index)\n","        \n","        return df_count\n","    \n","    amyg_count = create_value_count(amyg, 'AmygEFP downregulation')\n","    mesolimbic_count = create_value_count(mesolimbic, 'Mesolimbic upregulation')\n","    \n","    #concat value count df's\n","    total_count = pd.concat([amyg_count, mesolimbic_count], ignore_index = True)\n","    total_count.drop(columns = [3,4], inplace= True)\n","    \n","    if ('Valence' in features) or ('Arousal' in features):\n","        #change data structure for changing feature label\n","        total_count = total_count.melt(id_vars= ['Feature', 'Neural_Target', 'total_count'], value_vars = ['Yes', 'No'], value_name= 'count')\n","        \n","        #change feature label \n","        for i in range(len(total_count)):\n","            if (total_count.loc[i, 'Feature'] == 'Arousal') and (total_count.loc[i, 'variable'] == 'Yes'):\n","                total_count.loc[i, 'Feature'] = 'Low Arousal'\n","            if (total_count.loc[i, 'Feature'] == 'Arousal') and (total_count.loc[i, 'variable'] == 'No'):\n","                total_count.loc[i, 'Feature'] = 'High Arousal'\n","            if (total_count.loc[i, 'Feature'] == 'Valence') and (total_count.loc[i, 'variable'] == 'Yes'):\n","                total_count.loc[i, 'Feature'] = 'Negative Valence'\n","            if (total_count.loc[i, 'Feature'] == 'Valence') and (total_count.loc[i, 'variable'] == 'No'):\n","                total_count.loc[i, 'Feature'] = 'Positive Valence'\n","        \n","        #add proportion column\n","        total_count['yes_proportion'] = total_count['count'] / total_count['total_count']\n","        #change column order\n","        total_count = total_count[['Feature', 'count', 'total_count', 'yes_proportion', 'Neural_Target']]\n","        #sort by neural target column\n","        total_count = total_count.sort_values(by=['Neural_Target'])\n","        total_count = total_count.reset_index(drop = True)\n","\n","\n","    return total_count\n","\n","content_count = organize_data_for_plotting(data, content_features)\n","psychological_dimensions_count = organize_data_for_plotting(data, psychological_dimensions_features)\n","manner_features_count = organize_data_for_plotting(data, manner_features)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXReCnbMfKrs"},"outputs":[],"source":["def create_spyder_plot(df, features_for_plot, title):\n","    \n","    df_amygdala = df[df['Neural_Target'] == 'AmygEFP downregulation']\n","    df_mesolimbic = df[df['Neural_Target'] == 'Mesolimbic upregulation']\n","    df_amygdala  = df_amygdala[df_amygdala['Feature'].isin(features_for_plot)].reset_index(drop = True) \n","    df_mesolimbic = df_mesolimbic[df_mesolimbic['Feature'].isin(features_for_plot)].reset_index(drop = True) \n","\n","    # ------- PART 1: Create background\n","     \n","    # number of variable\n","    categories = list(df_amygdala['Feature'])\n","    N = len(categories)\n","    # What will be the angle of each axis in the plot? (we divide the plot / number of variable)\n","    angles = [n / float(N) * 2 * pi for n in range(N)]\n","    angles += angles[:1]\n","    # Initialise the spider plot\n","    ax = plt.subplot(111, polar=True)\n","    # If you want the first axis to be on top:\n","    ax.set_theta_offset(pi / 2)\n","    ax.set_theta_direction(-1)\n","    # Draw one ax per variable + add labels\n","    plt.xticks(angles[:-1], categories)\n","    # Draw ylabels\n","    y_ticks = [i/100 for i in range(0, 110, 10)]\n","    ax.set_rlabel_position(0)\n","    plt.yticks(y_ticks, [str(x) for x in y_ticks], color=\"black\", size=7)\n","    plt.ylim(0,1)\n","    \n","    # ------- PART 2: Add plots\n","              \n","    # Ind1\n","    values= df_amygdala['yes_proportion'].values.flatten().tolist()\n","    values += values[:1]\n","    ax.plot(angles, values, color = 'purple', linewidth=1, linestyle='solid', label=\"Amygdala downregulation\")\n","    ax.fill(angles, values, 'b', alpha=0.1)\n","     \n","    # Ind2\n","    values= df_mesolimbic['yes_proportion'].values.flatten().tolist()\n","    values += values[:1]\n","    ax.plot(angles, values, color = 'coral', linewidth=1, linestyle='solid', label=\"Mesolimbic upregulation\")\n","    ax.fill(angles, values, 'b', alpha=0.1)\n","     \n","    # Add legend\n","    plt.legend(loc='lower left', prop={'size': 10}, bbox_to_anchor=(-0.25,-0.25), borderaxespad=0)\n","    \n","    #Add title\n","    plt.title(title,pad=15)\n","    \n","    # Show the graph    \n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdFvlmP7fcBC"},"outputs":[],"source":["# As some content features and extremely rare (approximately all 'Nan' or 'No'), no need to plot them. Choose which feature to plot according to data\n","content_subset = ['Vision_Imagery', 'Auditory_Imagery', 'Tactile_Imagery'\n","          'Breathing','Lingual','Memory_or_Imaginative', 'Motor_Imagery',\n","          'Vision_Exteroception','Auditory_Exteroception',\n","          'Intercation_with_other_people']\n","\n","create_spyder_plot(psychological_dimensions_count,['High Arousal', 'Positive Valence', 'Low Arousal', 'Negative Valence'], 'Psychological Dimensions')\n","create_spyder_plot(content_count, content_subset,'Content Features')\n","create_spyder_plot(manner_features_count, list(manner_features_count['Feature'].unique()),'Manner Features')"]},{"cell_type":"markdown","metadata":{"id":"jKY-uM2_ijBA"},"source":["Inspecting the frequency of the features, we can see a phenomenological difference between the mental spaces of both groups on some features (e.g. content features of vision exteroception, interaction with other people, and positive vs negative valence in the psychological dimensions)"]},{"cell_type":"markdown","metadata":{"id":"Fj10A7aliqdM"},"source":["#  Section 2 - Dimensionality reduction of the mental space - SVD analysis\n","\n","The MSQ defines a rich and inclusive phenomenological space with multiple mental features of various categories. However, as done in other fields when quantifying high-dimensional spaces, we might want to find out whether these features are consistently clustered together in intelligable ways that we may not anticipate. Revealing the structure of clustering can provide a more compact, data-driven description of the mental space subjects actually explore (as opposed to our theoretical assumptions regarding types of mental meta-categories such as perception/imagery etc.), and therefore allowing us to better characterize its interaction with regulation success.\n","\n","To acheive this, we will use an established dimensionality reduction method, termed \"Singular Value Decomposition\" (SVD) analysis. This method will detect statistical patterns (such as covariances between specific MSQ features), and will result in a small number of general mental dimensions, or SVD components, accounting for clusters of MSQ features associations.\n","\n","\n","---\n","\n","\n","In order to run SVD on this dataset we first need to extract only the features values for a subset of amygdala down-regulation. We will also replace NaN values with 0.5 as these represent ambiguous feature values.   \n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0AnPg0UyjODI"},"outputs":[],"source":["from scipy.linalg import svd\n","from statsmodels.multivariate.factor_rotation import rotate_factors\n","\n","svd_data = data.loc[data['Neural_Target']==1]\n","svd_data = svd_data.iloc[:,7:]\n","txt = svd_data.columns\n","txt = txt.str.replace('_',' ') # fix txt for plotting\n","svd_data = svd_data.fillna(0.5) # replace NaN with 0.5"]},{"cell_type":"markdown","metadata":{"id":"62iGQ3ChmPP6"},"source":["It is a common practice to center the data\n","(i.e., decrease the entries in matrix columns by column means)\n","before conducting SVD to improve the interpretability of the SVD\n","dimensions. This is because the first SVD dimension extracted\n","from noncentered data is strongly correlated with the frequencies\n","of the objects in rows and columns. As the remaining dimensions\n","have to be orthogonal to the first one, the resulting SVD dimensions may not represent the data well"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WIuAP0fokTZ0"},"outputs":[],"source":["ct_svd_data = svd_data.apply(lambda x: x-x.mean()).to_numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E-_WJUVcm9rM"},"outputs":[],"source":["# Run SVD first on centered data\n","U, S, V = svd(ct_svd_data, lapack_driver='gesvd')"]},{"cell_type":"markdown","metadata":{"id":"LMy2zPH7ni-8"},"source":["We need to select how many components to keep from the analysis, one way is to use the 'elbow criterion' - We plot the percent variance explained by each feature and observe where additional features add very little information.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qPVshnvUn3RP"},"outputs":[],"source":["percS=S/np.sum(S)\n","\n","plt.plot(percS)\n","plt.title(\"Centered data - %variance exp.\")\n","#fig.savefig('variance_explained_py.jpg')"]},{"cell_type":"markdown","source":["Now we need to decide how many components to use. Generally, we use an 'elbow' criterion, which states that when the graphs become linear, adding components does not contribute substantially to the overall explained variance of the data. "],"metadata":{"id":"c6vD0TO96aHd"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-cWYDtApzny"},"outputs":[],"source":["# Choose number of components\n","numComponents=4 \n","ct_numComponents=4 \n","\n","V_small=V.T[:,:numComponents]  # The output of the SVD algorithm gives V transposed"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fySdR4IXqQay"},"outputs":[],"source":["#Plot Weights for Selected Components\n","fig, ax = plt.subplots(figsize=(10,10))\n","ax.imshow(V_small,aspect='auto',vmin=-0.5,vmax=0.5)\n","ax.set_title(\"Weights for SVD components\")\n","plt.colorbar(im)\n","ax.set_yticklabels(txt)\n","ax.set_yticks(np.arange(len(txt)))\n","ax.set_xticks(np.arange(numComponents))\n","ax.set_xticklabels(np.arange(numComponents))\n","ax.set_xlabel('Components')"]},{"cell_type":"markdown","source":["Each component is composed of all the MSQ features with different weights. Features given weights in the same direction are more likely to be included (or not included) in the represented mental space."],"metadata":{"id":"6ayqAQDhFKvF"}},{"cell_type":"markdown","metadata":{"id":"E6N0gj09sEnf"},"source":["Next, let get scores for each subject. These can later be use in modeling."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fJa1xwlmsT9Q"},"outputs":[],"source":["SVD_score = np.dot(ct_svd_data,V_small); # this step takes us from feature space to svd component space\n","pred = np.dot(SVD_score,V_small.T) # and back to feature space using only the selected components\n","\n","correlations = np.zeros((ct_svd_data.shape[1]))\n","for col in np.arange(ct_svd_data.shape[1]):\n","    correlations[col] = np.corrcoef(ct_svd_data[:,col],pred[:,col])[1,0] \n","\n","np.mean(correlations)"]},{"cell_type":"markdown","source":["We can see that now, each strategy is categorized along 4 components that compactly represent the whole MSQ space.\n","\n","Now let's understand what is the link between the MSQ space and the SVD components. To do so, we can inspect a strategy that recieved high negative and positive values for a specific component, and compare it with its original MSQ categories "],"metadata":{"id":"h94z1smzwBxU"}},{"cell_type":"code","source":["print(SVD_score[np.argmax((SVD_score[:,1]))])\n","svd_data.iloc[np.argmax((SVD_score[:,1])),:]"],"metadata":{"id":"79EnPTbIxCDB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["For this strategy, the SVD score of component 1 is positive and high. We expect a correspondence between component weigths and the MSG categories. For example, 'Vision Imagery' has a large positive weight and is **present** in the strategy. Likewise, 'Rythmic' has a large negative weight and is **not present** in the strategy."],"metadata":{"id":"x-v66wpzyrnl"}},{"cell_type":"code","source":["print(SVD_score[np.argmax(np.abs(SVD_score[:,1]))])\n","svd_data.iloc[np.argmax(np.abs(SVD_score[:,1])),:]"],"metadata":{"id":"iK1_rOP2twck"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here, when the SVD score for component 1 is very low, we expect that each strong weight in this component will be anti-correlated with the MSQ categories (large positive weights will indicate '0', and large negative weights will indicate '1'. Check if that's actually the case."],"metadata":{"id":"ScuEJ5DDxCR3"}},{"cell_type":"markdown","metadata":{"id":"Df3NM2LHtGco"},"source":["# Section 3 - Interactions between mental features and regulation success - Mixed Linear Effects (MLE) regression analyses\n","\n","To keep things simple, we will look only on the amygdala downregulation subset (N=4114 trials). We will test the difference in regulation success between instances of Yes's and No's, ignoring NaN values, for each feature seperately.\n","\n","Sparsity of a certain feature does not need to worry us - since the statistical test intrinsically penalizes small sample sizes - which will need a larger effect size to pass significance threshold. However, the proportion between 'Yes's and 'No's may be too unbalanced (e.g. 99% yes and 1% no) to representative of the population, but nevertheless produce significant results. There is no clear-cut criterion here. Roughly considering the size of our dataset and its sparsity, we chose to perform tests only on features that have at least 10% of both categories. This is adressed below in the code.\n","\n","We use mixed linear models to account for the nested hierarchical structure of the data (multiple time points per session, per subject), and to allow for missing time points (which is not enabled in standard repeated measures ANOVA)\n","the model: \n","\n","regulation success ~ 1 + msq_feature + (1|sub/ses) + Ïµ.\n","\n","The independent variable of regulation success - Qhat; the explanatory variable - msq feature (fixed effect), and two nested random effects we want to control for (subject/session). \n","\n","In lmer R the syntax would simply be: Qhat ~ msq_feature + (1|sub/ses). Here we are using Python's statsmodels, which implements our model as follows: \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tjVC0sKjuIAQ"},"outputs":[],"source":["import statsmodels.formula.api as smf\n","\n","df = data[data['Neural_Target']==1]\n","\n","mlem_stats = pd.DataFrame()\n","for msq_ftr in df.columns[7:]:\n","    cur_test_data = df[[\"sub_num\",\"session_num\",\"cycle_num\",\"Qhat\",msq_ftr]]\n","    cur_test_data.dropna(inplace=True) # drop 'Nan's\n","    \n","    # calculate yes/all data (yes+no) ratio \n","    if cur_test_data[msq_ftr].isin([1]).any():\n","        yes_no_ratio = cur_test_data[msq_ftr].value_counts()[1]/len(cur_test_data)\n","    else:\n","        yes_no_ratio = 0\n","    if yes_no_ratio > 0.1 and yes_no_ratio <0.9: # check if the ratio is between 0.1 and 0.9\n","        md = smf.mixedlm(f\"Qhat ~ {msq_ftr}\", data = cur_test_data, re_formula=\"1\", vc_formula={\"session_num\": \"0 + C(session_num)\",\"cycle_num\": \"0 + C(cycle_num*session_num)\"},groups=\"sub_num\")\n","        mdf = md.fit()\n","        print(mdf.summary())\n","        mlem_stats = pd.concat([mlem_stats,mdf.summary().tables[1].iloc[1][2:4]],axis=1) # MAYBE ADD THE Ns"]},{"cell_type":"code","source":["mlem_stats.T"],"metadata":{"id":"S1lN32Ua1DwT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HmSSR--QwX6P"},"source":["We can see various significant effects of the interaciton between regulation success and MSQ features. \n","\n","Let's plot the significant results to get a better grasp of these effets. For each significant MSQ feature, we will plot the difference between mean regulation success levels when feature was used ('Yes'group) and when it was not used ('No' group).  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aXo_0t9PujoF"},"outputs":[],"source":["def plot_qhat_diff(df, features_for_plot:list, title:str):\n","           \n","    #create df summary of qhat mean for each feature \n","    features = list(df)[4:48]\n","        \n","    #create list of Qhat mean for yes/ no \n","    qhat_yes_mean = []\n","    for feat in features:\n","        mean_yes = df[df[feat]==1]['Qhat'].mean()\n","        qhat_yes_mean.append(mean_yes)\n","        \n","    qhat_no_mean = []\n","    for feat in features:\n","        mean_no = df[df[feat]==0]['Qhat'].mean()\n","        qhat_no_mean.append(mean_no)\n","        \n","    #add lists to df\n","    qhat_means = pd.DataFrame([qhat_no_mean, qhat_yes_mean], columns = features)\n","        \n","    #arrange index\n","    no_yes = ['no', 'yes']\n","    qhat_means.index = no_yes\n","        \n","    qhat_means = qhat_means.transpose()\n","        \n","    #change features to columns \n","    qhat_means = qhat_means.reset_index()\n","    qhat_means = qhat_means.rename(columns = {'index': 'feature'})\n","        \n","    #add diff column\n","    qhat_means['diff'] = qhat_means['yes'] - qhat_means['no']\n","        \n","    #only include features you want to plot\n","    df_qhat_means_for_plotting = qhat_means.loc[qhat_means['feature'].isin(features_for_plot)]\n","    \n","    #sort values \n","    df_qhat_means_for_plotting.sort_values(by=['diff'],ascending = False, inplace = True)\n","    df_qhat_means_for_plotting.reset_index(drop = True, inplace= True)\n","    \n","    ## ploting:\n","    # create list of colors for plotting\n","    colors= []\n","    for i in range(len(df_qhat_means_for_plotting)):\n","        if df_qhat_means_for_plotting.loc[i, 'diff'] > 0:\n","            colors.append('salmon')\n","        else:\n","            colors.append('limegreen')\n","        \n","    #control for bar width\n","    def change_width(ax, new_value) :\n","        for patch in ax.patches :\n","            current_width = patch.get_width()\n","            diff = current_width - new_value\n","    \n","            # we change the bar width\n","            patch.set_width(new_value)\n","    \n","            # we recenter the bar\n","            patch.set_x(patch.get_x() + diff * .5)\n","    \n","    #change feature name for plot\n","    feature_label = {'Vision_Exteroception' : 'Sensory Vision',\n","                     'Auditory_Exteroception': 'Sensory Auditory',\n","                     'Smell_Exteroception': 'Sensory Smell',\n","                     'Taste_Exteroception': 'Sensory Taste',\n","                     'Tactile_Exteroception': 'Sensory Tactile',\n","                     'Viceral_sensations': 'Viceral Sensations',\n","                     'Muscle_sensation': 'Muscle Sensation',\n","                     'Vision_Imagery': 'Vision Imagery',\n","                     'Auditory_Imagery': 'Auditory Imagery',\n","                     'Smell_Imagery': 'Smell Imagery',\n","                     'Taste_Imagery': 'Taste Imagery',\n","                     'Tactile_Imagery': 'Tactile Imagery',\n","                     'Memory_or_Imaginative': 'Memory',\n","                     'Motor_Imagery': 'Motor Imagery',\n","                     'Lingual': 'Lingual',\n","                     'Conceptual_Arithmetic': 'Conceptual-Arithmetic' ,\n","                     'Rhythmic': 'Rhythmic',\n","                     'Interface_Engaged_Detached': 'Interface Engagement ',\n","                     'Involving_one_or_many_strategies': 'One Strategy',\n","                     'Arousal': 'Low Arousal',\n","                     'Valence': 'Negative Valence',\n","                     'Intercation_with_other_people': 'Social'}\n","    \n","    x_tick_feature_labels = [feature_label.get(item,item) for item in features_for_plot]\n","            \n","    #plot\n","    sns.set_theme(style='darkgrid')\n","    fig = sns.barplot(x='feature', y='diff', data=df_qhat_means_for_plotting , palette=colors)\n","    fig.set_xticklabels(x_tick_feature_labels)\n","    fig.tick_params(axis='x', rotation=90, labelsize=10) \n","    fig.set(ylim=(-0.1, 0.15))\n","    fig.set_xlabel(\"\",fontsize=15)\n","    fig.set_ylabel(\"Down Regulation           Up Regulation\", fontsize=12)\n","    \n","    fig.set_title(title, fontsize=15)\n","    \n","    change_width(fig, .5)\n","    \n","    #plt.savefig(path, bbox_inches= 'tight', dpi = 500)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7SY3ZKPEwplB"},"outputs":[],"source":["## the features to plot are manually defined here. Of course this could be derived automatically from the results above. \n","sig_MSQ_ftr_list = ['Vision_Exteroception', 'Auditory_Exteroception',\n","             'Auditory_Imagery', 'Motor_Imagery', 'Lingual',\n","             'Interface_Engaged_Detached', 'Involving_one_or_many_strategies',\n","             'Arousal', 'Valence', 'Intercation_with_other_people',\n","             'Happiness', 'Calmness', 'Agency']\n","\n","plot_qhat_diff(df, sig_MSQ_ftr_list, 'Mental Features Influence on NF Success')"]},{"cell_type":"markdown","metadata":{"id":"udUtbENpw3xl"},"source":["Remember that in this subset subjects were trying to down-regulate their signal.\n","Therefore, we can see that among the significant effects, some features indicate succesful down-regulation (e.g. Agency, Calmness, Happiness etc.) while other mental features indicate an opposite effect! (e.g. Sensory vision, Sensory Auditory, Auditory imagery, etc.)\n","Notably, both effects are of interest, even in clinical contexts - in order to know which features are good candidates for regulation, as well as which features one should avoid.\n","\n","We can also check whether the SVD components, which are a more compact description of the mental space of subjects, are linked with regulation success. Here we'll use a combined mixed linear regression model (including all SVD components in the model as fixed effects), since the SVD components are intrinsically uncorrelated (we can check this explicitly as well), hence no risk of colinearity between regressors.\n"]},{"cell_type":"code","source":["df1=data.loc[data['Neural_Target']==1,['sub_num','session_num','cycle_num','Qhat']].reset_index()\n","df2=pd.DataFrame(SVD_score, columns=['svd_comp1','svd_comp2','svd_comp3','svd_comp4']).reset_index()\n","svd_test_data=pd.concat([df1,df2],axis=1)\n","svd_test_data=svd_test_data[:4000]"],"metadata":{"id":"agleZMy339KF"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_ryS9paxBvq"},"outputs":[],"source":["svd_test_data.dropna(inplace=True) # drop 'Nan's\n","md_svd = smf.mixedlm(\"Qhat ~ svd_comp1 + svd_comp2 + svd_comp3 + svd_comp4\", data = svd_test_data, re_formula=\"1\", vc_formula={\"session_num\": \"0 + C(session_num)\",\"cycle_num\": \"0 + C(cycle_num*session_num)\"},groups=\"sub_num\")\n","mdf_svd = md_svd.fit()"]},{"cell_type":"code","source":["mdf_svd.summary()"],"metadata":{"id":"zXG9KwPr_bTm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fQInsRgnxl4T"},"source":["# Section 4 - Exploration dynamics of the mental space of subjects - Cosine similarity analyses\n","\n","In stage 1 we looked at frequencies of mental features of subjects across different groups. This descriptive analysis gave us an average snap-shot of the typical mental space subjects explore during practice. \n","\n","However, if we wish to relate exploration of strategies along practice to regulation learning, i.e. the CHANGE in regulation levels along training, we will want to examine how the mental space temporally unfolds along practice, and whether certain types of mental exploration trajectories relate to regulation learning.\n","\n","To unpack this \"black box\" using MSQ data, we can quantify the similarity between strategies according to their vectorial (MSQ as well as its SVD reduction) characterization, and examine how similaritiy between strategies changes along practice, either in a trial-by-trial dynamics, or, for a more temporally smoothed measure, per session. \n","\n","Plotting these patterns could shed first light on a key feature of NF value-based learning - exploration-exploitation tradeoffs of internal actions during NF practice. \n","\n","To quantify the similarity between the vectorial characterization of stratgies, we apply a common measure termed cosine similarity. Cosine similarity characterizaes the distance (i.e. the difference) between two vectors, such as the MSQ features vectors per strategy. Specifically, we use an adjusted variant measure named \"soft cosine\", that takes into account the interactions between different features by wieghting the measure with the correlation matrix between features.  \n"]},{"cell_type":"markdown","metadata":{"id":"BuEBzKMVyvo_"},"source":["The following function receives two vectors of MSQ features, the general correlation matrix, and returns a value between 0 (copmlete difference) and 1 (two identical strategies)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Le2s-bsZyc7i"},"outputs":[],"source":["def soft_cos_calc(a, b, sim_matrix):\n","    \n","    #nominator calculation\n","    sum_nominator = 0\n","    for i in range(len(a)):\n","        for j in range(len(b)):\n","            sum_nominator += (sim_matrix[i,j])*(a[i])*(b[j])\n","    \n","    #denominator nrom values calculation\n","    sum_norm_a= 0\n","    for i in range(len(a)):\n","        for j in range(len(a)):\n","            sum_norm_a += sim_matrix[i,j]*(a[i])*(a[j])\n","    norm_a = np.sqrt(sum_norm_a)\n","    \n","    sum_norm_b= 0\n","    for i in range(len(b)):\n","        for j in range(len(b)):\n","            sum_norm_b += sim_matrix[i,j]*(b[i])*(b[j])\n","    norm_b = np.sqrt(sum_norm_b)\n","    \n","    #calculate softcosine between a and b\n","    sftcos = sum_nominator/(norm_a*norm_b)\n","    \n","    return sftcos"]},{"cell_type":"markdown","metadata":{"id":"s9qWPdjty3_P"},"source":["Now we will calculate it for each two adjacent strategies, per session, per subject, to uncover how subjects explore their mental space. \n"]},{"cell_type":"code","source":["from os import replace\n","# removing irrelevant columns from data (Taste-exteroception feature has only 0 (No) values, which will cause problems with similarity calculations)\n","sim_data = df.drop(columns=['Qhat','Cohens_D','Taste_Exteroception','Study','Neural_Target'],axis=1).reset_index(drop=True)\n","\n","sim_data = sim_data.fillna(0)\n","sim_data = sim_data.astype(int)\n","\n","msq_features = list(sim_data)[3::]\n","\n","# calculate correlation matrix between features\n","corr_matrix = sim_data[msq_features].corr()\n","\n","# convert data to numpy arrays\n","sim_data_matrix = sim_data.to_numpy()\n","corr_matrix = corr_matrix.to_numpy()\n","\n","\n","# create a new dataframe for exploration measures\n","exploration = pd.DataFrame({'sub_num': [],\n","                            'session_num': [],\n","                            'strategy_n': [],\n","                            'strategy_n+1': [],\n","                            'soft_cos_similarity': []})\n","\n","# fill rows with all adjacent strategies\n","for i in range(len(sim_data)-1):\n","    y = i+1\n","    if (sim_data.loc[i, 'sub_num'] == sim_data.loc[y, 'sub_num']) & (sim_data.loc[i, 'session_num'] == sim_data.loc[y, 'session_num']) & (sim_data.loc[i, 'cycle_num'] < sim_data.loc[y, 'cycle_num']):\n","        exploration.loc[i, 'sub_num'] = sim_data.loc[i, 'sub_num']\n","        exploration.loc[i, 'session_num'] = sim_data.loc[i, 'session_num']\n","        exploration.loc[i, 'strategy_n'] = sim_data.loc[i, 'cycle_num']\n","        exploration.loc[i, 'strategy_n+1'] = sim_data.loc[y,'cycle_num']\n","\n","\n","# calculate soft cosine for each pair of cycles in data_matrix\n","soft_cosine_lst = []\n","for t in range(len(sim_data_matrix)-1):\n","    cur_soft_cos = soft_cos_calc(sim_data_matrix[t, 3::], sim_data_matrix[t+1, 3::], corr_matrix)\n","    soft_cosine_lst.append(cur_soft_cos)\n","\n","soft_cosine_lst.append(0)\n","soft_cosine_lst =  [0 if math.isnan(x) else x for x in soft_cosine_lst]\n","\n","# add soft cos calculation to sim_data df\n","sim_data['soft_cos_similarity'] = soft_cosine_lst\n","\n","# extract the relevant rows for exploration (excuding pairs of different subjects or sessions)\n","valid_pairs = sim_data\n","\n","for i in range(len(valid_pairs)-1):\n","    y= i+1\n","    if not ((valid_pairs.loc[i, 'sub_num'] == valid_pairs.loc[y, 'sub_num']) & (valid_pairs.loc[i, 'session_num'] == valid_pairs.loc[y, 'session_num']) & (valid_pairs.loc[i, 'cycle_num'] < valid_pairs.loc[y, 'cycle_num'])):\n","        valid_pairs.drop(index = i, inplace= True)\n","valid_pairs = valid_pairs.iloc[:-1 , :]\n","\n","# copy soft_cos to exploration df\n","exploration['soft_cos_similarity'] = valid_pairs['soft_cos_similarity']\n","#save exploration to excel\n","# let's plot similarity across adjacent strategies across all subjects:\n","fig=plt.hist(exploration['soft_cos_similarity'], bins = 20) \n"],"metadata":{"id":"dt2U0bcPB1C0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sim_data.head()"],"metadata":{"id":"59XL67qFELs4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mr6yWfGh2w1u"},"source":["We can see that many adjacent strategies are actually a repeated strategy ( soft_cos = 1), but that there are many other instances of changing the strategy to various degrees (soft_cas < 1).\n","\n","Now let's plot the time course of two representative subjects with differing exploration trajectories:\n","\n","- A subject that zig-zags between strategies:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvuUriZL25nI"},"outputs":[],"source":["zigzag_sub = exploration[exploration['sub_num']==12]    \n","plt.plot(zigzag_sub.index,zigzag_sub['soft_cos_similarity'],'-o')"]},{"cell_type":"markdown","metadata":{"id":"ufaZPncd28ND"},"source":["- Another subject that continueously explores their mental space (see that the values are lower):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UzMlnxnL2_25"},"outputs":[],"source":["uncertain_sub = exploration[exploration['sub_num']==13]    \n","plt.plot(uncertain_sub.index,uncertain_sub['soft_cos_similarity'],'-o')"]},{"cell_type":"markdown","metadata":{"id":"zuGR2dkS3CMj"},"source":["- A subject that rarely explores their mental space:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TXEpOj0W3GuE"},"outputs":[],"source":["rigid_sub = exploration[exploration['sub_num']==2872]    \n","plt.plot(rigid_sub.index,rigid_sub['soft_cos_similarity'],'-o')"]},{"cell_type":"markdown","metadata":{"id":"Tirb8Z5g3GDO"},"source":["- And finally, a subject that gradually converges on a specific strategy/mental space:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59ynBhWu3PCb"},"outputs":[],"source":["converging_sub = exploration[exploration['sub_num']==5862]    \n","plt.plot(converging_sub.index,converging_sub['soft_cos_similarity'],'-o')"]},{"cell_type":"markdown","metadata":{"id":"3acxGjTd3P4L"},"source":["These cherry-picked types of exploration trajectories illustrate how subjects' exploration differ qualitatively.\n","Importantly, these estimations can be used for various quantitative analyses:\n","1. Characterizing these exploration trajectories in a data-driven manner, using pattern analysis methods that suit logitudinal data. \n","2. Averaging values per subject to use as individual NF exploration measures, e.g. correlating them with other treatment outcomes. \n","3. Assessing the link between levels of exploration and regulation success along practice. This latter option is exhibited in Poster number ***W26***!\n"]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}